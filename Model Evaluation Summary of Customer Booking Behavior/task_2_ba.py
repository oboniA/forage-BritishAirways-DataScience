# -*- coding: utf-8 -*-
"""Task_2_BA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i6nyIaHUuyURuOormnrluOkDAH25KdWp

# Task 2

---

## Predictive modeling of customer bookings

This Jupyter notebook includes some code to get you started with this predictive modeling task. We will use various packages for data manipulation, feature engineering and machine learning.

### Exploratory data analysis

First, we must explore the data in order to better understand what we have and the statistical properties of the dataset.
"""

import pandas as pd

df = pd.read_csv("data/customer_booking.csv", encoding="ISO-8859-1")
df.head(10)

"""The `.head()` method allows us to view the first 5 rows in the dataset, this is useful for visual inspection of our columns"""

# summary of the dataset
df.describe()

"""The `.describe()` method gives us a summary of descriptive statistics over the entire dataset (only works for numeric columns). This gives us a quick overview of a few things such as the mean, min, max and overall distribution of each column.

From this point, you should continue exploring the dataset with some visualisations and other metrics that you think may be useful. Then, you should prepare your dataset for predictive modelling. Finally, you should train your machine learning model, evaluate it with performance metrics and output visualisations for the contributing variables. All of this analysis should be summarised in your single slide.
"""

# check for null or missing values
df.isnull().sum()

# drop rows with missing values if any
df = df.dropna()

"""Data types of each column"""

df.info()

"""The `.info()` method gives us a data description, telling us the names of the columns, their data types and how many null values we have. Fortunately, we have no null values. It looks like some of these columns should be converted into different data types, e.g. flight_day.

To provide more context, below is a more detailed data description, explaining exactly what each column means:

- `num_passengers` = number of passengers travelling
- `sales_channel` = sales channel booking was made on
- `trip_type` = trip Type (Round Trip, One Way, Circle Trip)
- `purchase_lead` = number of days between travel date and booking date
- `length_of_stay` = number of days spent at destination
- `flight_hour` = hour of flight departure
- `flight_day` = day of week of flight departure
- `route` = origin -> destination flight route
- `booking_origin` = country from where booking was made
- `wants_extra_baggage` = if the customer wanted extra baggage in the booking
- `wants_preferred_seat` = if the customer wanted a preferred seat in the booking
- `wants_in_flight_meals` = if the customer wanted in-flight meals in the booking
- `flight_duration` = total duration of flight (in hours)
- `booking_complete` = flag indicating if the customer completed the booking

Before we compute any statistics on the data, lets do any necessary data conversion

**Checks for unique values in each column**
"""

df.columns

for col in df.columns:
    print(f"{col}: {df[col].nunique()} unique values")
    print(df[col].unique())
    print("-" * 50)

"""**Feature engineering**

1. map categorical days of the week into numerical format
"""

df["flight_day"].unique()

mapping = {
    "Mon": 1,
    "Tue": 2,
    "Wed": 3,
    "Thu": 4,
    "Fri": 5,
    "Sat": 6,
    "Sun": 7,
}

df["flight_day"] = df["flight_day"].map(mapping)

df["flight_day"].unique()

"""**visualize distributions and relationships between variables.**"""

import matplotlib.pyplot as plt
import seaborn as sns

# distribution of target variable (booking_complete)
sns.countplot(x='booking_complete', data=df)
plt.title('Distribution of Booking Completion')
plt.show()

# analyze categorical features
sns.countplot(y='sales_channel', hue='booking_complete', data=df)
plt.title('Sales Channel vs Booking Completion')
plt.show()

"""**Shows all the categorical columns [type object]**"""

print(df.dtypes)

"""OR also can be found as,"""

# how columns with object type
cat_cols = df.select_dtypes(include=['object']).columns
print("Categorical columns based on data type:")
print(cat_cols)

"""Notice, since trip_day is mapped to numerical value, it is not present in the categorical list anymore as an object.

2. perform one-hot encoding on the sales_channel and trip_type categorical variables
"""

# convert categorical variables to dummy variables
df = pd.get_dummies(df, columns=['sales_channel', 'trip_type', 'route', 'booking_origin'], drop_first=False)

# new features by combining other features
df['total_requests'] = df['wants_extra_baggage'] + df['wants_preferred_seat'] + df['wants_in_flight_meals']
print(df.head())

# drop unnecessary columns
df.drop(['flight_duration'], axis=1, inplace=True)

print(df.columns)

"""**Prepare Data for Modelling**"""

from sklearn.model_selection import train_test_split

# features and target variable
X = df.drop('booking_complete', axis=1)
y = df['booking_complete']

# split training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"Training size: {X_train.shape[0]}, Test size: {X_test.shape[0]}")

"""Training Random Forest Model"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# train Random Forest Classifier
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

"""****

**Model Evaluation**

Cross validation
to assess how well the model will generalize to an unseen dataset
"""

import numpy as np
from sklearn.model_selection import cross_val_score

# cross-validation
cv_scores = cross_val_score(rf_model, X, y, cv=5)  # 5-fold cross-validation

print("Cross-validation scores:", cv_scores)
print("Mean cross-validation score: {:.2f}%".format(np.mean(cv_scores) * 100))

# predictions
y_pred = rf_model.predict(X_test)

# evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

print("The model achieved an accuracy of {:.2f}% on the test data.".format(accuracy_score(y_test, y_pred) * 100))

from sklearn.metrics import roc_curve, auc

# ROC curve and ROC area
fpr, tpr, thresholds = roc_curve(y_test, rf_model.predict_proba(X_test)[:, 1])
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""**Feature importance**

Explains how each variable contributes to the model can help in interpretation
"""

# feature importances
feature_imp = rf_model.feature_importances_
features = X.columns

# create df for feature importances
imp_df = pd.DataFrame({'Feature': features, 'Importance': feature_imp})
imp_df = imp_df.sort_values(by='Importance', ascending=False)

# limit the number of features to display
top_n = 20  # Change this number based on your preference
imp_df = imp_df.head(top_n)

# Increase figure size and rotate labels for better readability
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=imp_df)
plt.title('Top Feature Importances from Random Forest Model')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.xticks(rotation=45)
plt.show()